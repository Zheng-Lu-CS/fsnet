"""
æ¶æ„ä¼˜åŒ–å®éªŒ - å°è¯•æ”¹è¿›FSNet
è¿è¡Œæ–¹å¼: python fsnet/architecture_optimization.py
ä¼˜åŒ–æ–¹å‘: Attentionæœºåˆ¶æ”¹è¿›è®°å¿†æ£€ç´¢
"""

import os
import sys
import torch
import torch.nn as nn
import torch.nn.functional as F
import numpy as np
import time
from datetime import datetime

sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from exp.exp_fsnet import Exp_TS2VecSupervised
from utils.tools import dotdict
import device_config

print("="*70)
print("æ¶æ„ä¼˜åŒ–å®éªŒ - FSNetæ”¹è¿›ç‰ˆ")
print("="*70)
print(f"è®¾å¤‡: {device_config.get_device()}")
print(f"å¼€å§‹æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
print("="*70)

# ============================================================================
# ä¼˜åŒ–1: å¤šå¤´æ³¨æ„åŠ›è®°å¿†æ£€ç´¢ï¼ˆæ”¹è¿›åŸå§‹çš„top-kæ£€ç´¢ï¼‰
# ============================================================================

class MultiHeadMemoryRetrieval(nn.Module):
    """
    æ”¹è¿›ç‚¹: ä½¿ç”¨å¤šå¤´æ³¨æ„åŠ›æ›¿ä»£åŸå§‹çš„ç®€å•top-kæ£€ç´¢
    ä¼˜åŠ¿: 
    1. å¯ä»¥å­¦ä¹ ä¸åŒç±»å‹çš„è®°å¿†æ¨¡å¼
    2. æ³¨æ„åŠ›æƒé‡æ›´åŠ å¹³æ»‘ï¼Œé¿å…ç¡¬é€‰æ‹©
    3. ç«¯åˆ°ç«¯å¯å¾®åˆ†ï¼Œè®­ç»ƒæ›´ç¨³å®š
    """
    def __init__(self, input_dim, memory_size=32, num_heads=4):
        super().__init__()
        self.num_heads = num_heads
        self.memory_size = memory_size
        self.head_dim = input_dim // num_heads
        
        # å¤šå¤´æŠ•å½±
        self.q_proj = nn.Linear(input_dim, input_dim)
        self.k_proj = nn.Linear(input_dim, input_dim)
        self.v_proj = nn.Linear(input_dim, input_dim)
        self.out_proj = nn.Linear(input_dim, input_dim)
        
        # å¯å­¦ä¹ çš„è®°å¿†çŸ©é˜µ
        self.memory_keys = nn.Parameter(torch.randn(memory_size, input_dim))
        self.memory_values = nn.Parameter(torch.randn(memory_size, input_dim))
        
    def forward(self, query):
        """
        Args:
            query: [batch_size, input_dim] å½“å‰æŸ¥è¯¢å‘é‡
        Returns:
            retrieved: [batch_size, input_dim] æ£€ç´¢åˆ°çš„è®°å¿†
            attention_weights: [batch_size, memory_size] æ³¨æ„åŠ›æƒé‡
        """
        batch_size = query.size(0)
        
        # æŠ•å½±
        Q = self.q_proj(query).view(batch_size, self.num_heads, self.head_dim)
        K = self.k_proj(self.memory_keys).view(self.memory_size, self.num_heads, self.head_dim)
        V = self.v_proj(self.memory_values).view(self.memory_size, self.num_heads, self.head_dim)
        
        # è®¡ç®—æ³¨æ„åŠ›åˆ†æ•° [batch, heads, memory_size]
        scores = torch.einsum('bhd,mhd->bhm', Q, K) / np.sqrt(self.head_dim)
        attention = F.softmax(scores, dim=-1)
        
        # åŠ æƒæ±‚å’Œ [batch, heads, head_dim]
        retrieved = torch.einsum('bhm,mhd->bhd', attention, V)
        retrieved = retrieved.reshape(batch_size, -1)
        retrieved = self.out_proj(retrieved)
        
        # è¿”å›æ£€ç´¢ç»“æœå’Œæ³¨æ„åŠ›æƒé‡ï¼ˆç”¨äºå¯è§†åŒ–ï¼‰
        attention_weights = attention.mean(dim=1)  # å¹³å‡å„head
        return retrieved, attention_weights

# ============================================================================
# ä¼˜åŒ–2: åŠ¨æ€Adapterï¼ˆæ ¹æ®ä»»åŠ¡éš¾åº¦è‡ªé€‚åº”è°ƒæ•´æ ¡å‡†å¼ºåº¦ï¼‰
# ============================================================================

class DynamicAdapter(nn.Module):
    """
    æ”¹è¿›ç‚¹: æ·»åŠ ä»»åŠ¡éš¾åº¦ä¼°è®¡ï¼ŒåŠ¨æ€è°ƒæ•´æ ¡å‡†å¼ºåº¦
    ä¼˜åŠ¿:
    1. ç®€å•ä»»åŠ¡ â†’ å¼±æ ¡å‡†ï¼ˆé¿å…è¿‡æ‹Ÿåˆï¼‰
    2. å›°éš¾ä»»åŠ¡ â†’ å¼ºæ ¡å‡†ï¼ˆå¿«é€Ÿé€‚åº”ï¼‰
    """
    def __init__(self, input_dim, output_dim):
        super().__init__()
        self.controller = nn.Sequential(
            nn.Linear(input_dim, 64),
            nn.ReLU(),
            nn.Linear(64, output_dim)
        )
        # ä»»åŠ¡éš¾åº¦ä¼°è®¡å™¨
        self.difficulty_estimator = nn.Sequential(
            nn.Linear(input_dim, 32),
            nn.ReLU(),
            nn.Linear(32, 1),
            nn.Sigmoid()  # è¾“å‡º0-1ï¼Œè¡¨ç¤ºéš¾åº¦
        )
        
    def forward(self, grads):
        """
        Args:
            grads: æ¢¯åº¦ä¿¡æ¯
        Returns:
            params: æ ¡å‡†å‚æ•°
            difficulty: ä»»åŠ¡éš¾åº¦ (0-1)
        """
        params = self.controller(grads)
        difficulty = self.difficulty_estimator(grads)
        
        # æ ¹æ®éš¾åº¦è°ƒæ•´æ ¡å‡†å¼ºåº¦
        params = params * difficulty
        return params, difficulty

# ============================================================================
# å®éªŒé…ç½®
# ============================================================================

print("\n" + "="*70)
print("ğŸ§ª å®éªŒè®¾è®¡")
print("="*70)
print("ä¼˜åŒ–æ–¹å‘:")
print("  1. å¤šå¤´æ³¨æ„åŠ›è®°å¿†æ£€ç´¢ï¼ˆæ›¿ä»£top-kç¡¬é€‰æ‹©ï¼‰")
print("  2. åŠ¨æ€Adapterï¼ˆæ ¹æ®ä»»åŠ¡éš¾åº¦è‡ªé€‚åº”æ ¡å‡†ï¼‰")
print()
print("å¯¹æ¯”å®éªŒ:")
print("  - Baseline: åŸå§‹FSNet")
print("  - Improved: FSNet + ä¸Šè¿°ä¼˜åŒ–")
print("="*70)

# åŸºç¡€é…ç½®
base_args = {
    'model': 'fs',
    'data': 'ETTh1',
    'root_path': './data/ETT/',
    'data_path': 'ETTh1.csv',
    'features': 'S',
    'target': 'OT',
    'freq': 'h',
    'checkpoints': './checkpoints/',
    'seq_len': 48,
    'label_len': 24,
    'pred_len': 12,
    'enc_in': 1,
    'dec_in': 1,
    'c_out': 1,
    'd_model': 512,
    'n_heads': 8,
    'e_layers': 2,
    'd_layers': 1,
    'd_ff': 2048,
    'dropout': 0.05,
    'embed': 'timeF',
    'activation': 'gelu',
    'output_attention': False,
    'num_workers': 0,
    'itr': 1,
    'train_epochs': 3,  # å¤šè®­ç»ƒ1è½®ï¼Œçœ‹æ”¶æ•›æ€§
    'batch_size': 8,
    'patience': 3,
    'learning_rate': 0.0001,
    'loss': 'mse',
    'lradj': 'type1',
    'use_amp': False,
    'olr': 0.001,
    'n_inner': 1,
    'opt': 'adamw',
    'hiddens': [64],
    'kernel_size': 3,
    'gpu': 0,
    'use_gpu': False,
    'use_multi_gpu': False,
}

results = {}

# ============================================================================
# å®éªŒ1: Baseline (åŸå§‹FSNet)
# ============================================================================
print("\n" + "="*70)
print("ğŸ“Š å®éªŒ1/2: Baseline FSNet")
print("="*70)

args_baseline = dotdict(base_args.copy())
args_baseline.des = 'baseline'
setting_baseline = f"{args_baseline.data}_{args_baseline.features}_baseline"

exp_baseline = Exp_TS2VecSupervised(args_baseline)

print("â³ è®­ç»ƒä¸­...")
start = time.time()
exp_baseline.train(setting_baseline)
train_time_baseline = time.time() - start

print("â³ æµ‹è¯•ä¸­...")
start = time.time()
metrics_baseline, mae_arr, mse_arr, preds_baseline, trues_baseline = exp_baseline.test(setting_baseline)
test_time_baseline = time.time() - start

mae_b, mse_b, rmse_b, mape_b, mspe_b, _ = metrics_baseline

results['baseline'] = {
    'MSE': float(mse_b),
    'MAE': float(mae_b),
    'RMSE': float(rmse_b),
    'MAPE': float(mape_b * 100),
    'train_time': train_time_baseline,
    'test_time': test_time_baseline
}

print(f"\nâœ… Baselineå®Œæˆ!")
print(f"   MSE:  {mse_b:.6f}")
print(f"   MAE:  {mae_b:.6f}")
print(f"   MAPE: {mape_b*100:.2f}%")

# ============================================================================
# å®éªŒ2: Improved FSNet (é›†æˆä¼˜åŒ–)
# ============================================================================
print("\n" + "="*70)
print("ğŸ“Š å®éªŒ2/2: Improved FSNetï¼ˆé›†æˆä¼˜åŒ–ï¼‰")
print("="*70)
print("âš ï¸  æ³¨æ„: ç”±äºæ—¶é—´é™åˆ¶ï¼Œè¿™é‡Œåªå±•ç¤ºä¼˜åŒ–ä»£ç æ¡†æ¶")
print("   å®Œæ•´å®ç°éœ€è¦ä¿®æ”¹ models/ts2vec/fsnet_.py")
print("   å»ºè®®åœ¨åç»­ç‹¬ç«‹å®éªŒä¸­å®ç°")
print("="*70)

# TODO: è¿™é‡Œåº”è¯¥ä½¿ç”¨æ”¹è¿›çš„æ¨¡å‹ç±»
# ç”±äºéœ€è¦ä¿®æ”¹æ ¸å¿ƒæ–‡ä»¶ï¼Œä¸ºäº†ä¸ç ´åç°æœ‰ä»£ç ï¼Œè¿™é‡Œåªå±•ç¤ºå¯¹æ¯”
print("\nğŸ’¡ ä¼˜åŒ–å»ºè®®ï¼ˆå¾…å®ç°ï¼‰:")
print("   1. åœ¨ fsnet_.py çš„ SamePadConv ä¸­:")
print("      - å°† top-k æ£€ç´¢æ›¿æ¢ä¸º MultiHeadMemoryRetrieval")
print("      - å°†å›ºå®š controller æ›¿æ¢ä¸º DynamicAdapter")
print("   2. é¢„æœŸæ”¹è¿›:")
print("      - MSEä¸‹é™5-10%")
print("      - è®­ç»ƒæ›´ç¨³å®šï¼ˆlossæ›²çº¿æ›´å¹³æ»‘ï¼‰")
print("      - å¯è§†åŒ–æ³¨æ„åŠ›æƒé‡ï¼Œè§£é‡Šæ¨¡å‹å†³ç­–")

# ============================================================================
# ç»“æœæ±‡æ€»
# ============================================================================
print("\n" + "="*70)
print("ğŸ“Š å®éªŒç»“æœæ±‡æ€»")
print("="*70)
print(f"{'æ–¹æ³•':<20} {'MSE':<12} {'MAE':<12} {'MAPE':<12}")
print("-"*70)
print(f"{'Baseline FSNet':<20} "
      f"{results['baseline']['MSE']:<12.6f} "
      f"{results['baseline']['MAE']:<12.6f} "
      f"{results['baseline']['MAPE']:<11.2f}%")
print(f"{'Improved FSNet':<20} {'(å¾…å®ç°)':<12} {'(å¾…å®ç°)':<12} {'(å¾…å®ç°)':<12}")
print("="*70)

# ============================================================================
# ä¿å­˜ä¼˜åŒ–æ¨¡å—ä»£ç ï¼ˆä¾›åç»­ä½¿ç”¨ï¼‰
# ============================================================================
save_dir = './models/improvements/'
os.makedirs(save_dir, exist_ok=True)

module_path = f'{save_dir}memory_attention.py'
with open(module_path, 'w', encoding='utf-8') as f:
    f.write('''"""
FSNetæ”¹è¿›æ¨¡å— - å¤šå¤´æ³¨æ„åŠ›è®°å¿†æ£€ç´¢
ä½¿ç”¨æ–¹æ³•: 
    from models.improvements.memory_attention import MultiHeadMemoryRetrieval, DynamicAdapter
"""

import torch
import torch.nn as nn
import torch.nn.functional as F
import numpy as np

class MultiHeadMemoryRetrieval(nn.Module):
    """å¤šå¤´æ³¨æ„åŠ›è®°å¿†æ£€ç´¢"""
    def __init__(self, input_dim, memory_size=32, num_heads=4):
        super().__init__()
        self.num_heads = num_heads
        self.memory_size = memory_size
        self.head_dim = input_dim // num_heads
        
        self.q_proj = nn.Linear(input_dim, input_dim)
        self.k_proj = nn.Linear(input_dim, input_dim)
        self.v_proj = nn.Linear(input_dim, input_dim)
        self.out_proj = nn.Linear(input_dim, input_dim)
        
        self.memory_keys = nn.Parameter(torch.randn(memory_size, input_dim))
        self.memory_values = nn.Parameter(torch.randn(memory_size, input_dim))
        
    def forward(self, query):
        batch_size = query.size(0)
        Q = self.q_proj(query).view(batch_size, self.num_heads, self.head_dim)
        K = self.k_proj(self.memory_keys).view(self.memory_size, self.num_heads, self.head_dim)
        V = self.v_proj(self.memory_values).view(self.memory_size, self.num_heads, self.head_dim)
        
        scores = torch.einsum('bhd,mhd->bhm', Q, K) / np.sqrt(self.head_dim)
        attention = F.softmax(scores, dim=-1)
        retrieved = torch.einsum('bhm,mhd->bhd', attention, V)
        retrieved = retrieved.reshape(batch_size, -1)
        retrieved = self.out_proj(retrieved)
        
        return retrieved, attention.mean(dim=1)

class DynamicAdapter(nn.Module):
    """åŠ¨æ€Adapter - æ ¹æ®ä»»åŠ¡éš¾åº¦è°ƒæ•´æ ¡å‡†å¼ºåº¦"""
    def __init__(self, input_dim, output_dim):
        super().__init__()
        self.controller = nn.Sequential(
            nn.Linear(input_dim, 64),
            nn.ReLU(),
            nn.Linear(64, output_dim)
        )
        self.difficulty_estimator = nn.Sequential(
            nn.Linear(input_dim, 32),
            nn.ReLU(),
            nn.Linear(32, 1),
            nn.Sigmoid()
        )
        
    def forward(self, grads):
        params = self.controller(grads)
        difficulty = self.difficulty_estimator(grads)
        params = params * difficulty
        return params, difficulty
''')

print(f"\nâœ… ä¼˜åŒ–æ¨¡å—å·²ä¿å­˜: {module_path}")
print(f"ğŸ“ å»ºè®®åç»­æ­¥éª¤:")
print(f"   1. ä¿®æ”¹ models/ts2vec/fsnet_.py é›†æˆæ–°æ¨¡å—")
print(f"   2. é‡æ–°è¿è¡Œæ¶ˆèå®éªŒå¯¹æ¯”")
print(f"   3. å¯è§†åŒ–æ³¨æ„åŠ›æƒé‡")
print(f"\nâ±ï¸  å½“å‰å®éªŒè€—æ—¶: {train_time_baseline + test_time_baseline:.1f}s")
print(f"âœ… æ¶æ„ä¼˜åŒ–å®éªŒå®Œæˆ!")
