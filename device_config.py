"""
å…¨å±€è®¾å¤‡é…ç½®æ–‡ä»¶
====================================
åœ¨è¿™é‡Œä¿®æ”¹USE_CUDAå°±èƒ½å…¨å±€åˆ‡æ¢CPU/GPU

ç”¨æ³•:
    from device_config import get_device
    device = get_device()
"""

import torch
import os

# ============================================
# ğŸ”§ å…¨å±€è®¾å¤‡é…ç½® - åªéœ€è¦æ”¹è¿™ä¸€ä¸ªåœ°æ–¹ï¼
# ============================================
USE_CUDA = False  # âœ… æ”¹ä¸º True å¯ç”¨GPUï¼ŒFalse ä½¿ç”¨CPU

# ============================================
# è‡ªåŠ¨è®¾å¤‡é€‰æ‹©é€»è¾‘ï¼ˆä¸éœ€è¦ä¿®æ”¹ï¼‰
# ============================================
def get_device(force_cpu=None):
    """
    è·å–å…¨å±€è®¾å¤‡
    
    å‚æ•°:
        force_cpu: å¼ºåˆ¶ä½¿ç”¨CPUï¼ˆè¦†ç›–å…¨å±€é…ç½®ï¼‰
    
    è¿”å›:
        torch.device: CPUæˆ–CUDAè®¾å¤‡
    """
    # å¼ºåˆ¶CPUæ¨¡å¼
    if force_cpu is not None and force_cpu:
        return torch.device('cpu')
    
    # ä½¿ç”¨å…¨å±€é…ç½®
    if USE_CUDA and torch.cuda.is_available():
        device = torch.device('cuda')
        print(f'[GPU] ä½¿ç”¨GPU: {torch.cuda.get_device_name(0)}')
        print(f'      æ˜¾å­˜: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB')
    else:
        device = torch.device('cpu')
        if USE_CUDA and not torch.cuda.is_available():
            print('[WARNING] é…ç½®äº†USE_CUDA=Trueä½†CUDAä¸å¯ç”¨ï¼Œå›é€€åˆ°CPU')
        else:
            print('[CPU] ä½¿ç”¨CPU')
    
    return device

def set_device_env():
    """è®¾ç½®CUDAç›¸å…³ç¯å¢ƒå˜é‡"""
    if not USE_CUDA:
        os.environ['CUDA_VISIBLE_DEVICES'] = ''
        print('[CONFIG] å·²ç¦ç”¨CUDAï¼ˆè®¾ç½®CUDA_VISIBLE_DEVICES="")')

# ============================================
# ä¾¿æ·å‡½æ•°
# ============================================
def is_cuda_available():
    """æ£€æŸ¥CUDAæ˜¯å¦å¯ç”¨"""
    return torch.cuda.is_available()

def get_device_info():
    """è·å–è®¾å¤‡ä¿¡æ¯"""
    device = get_device()
    info = {
        'device': str(device),
        'use_cuda': USE_CUDA,
        'cuda_available': torch.cuda.is_available(),
    }
    
    if device.type == 'cuda':
        info['gpu_name'] = torch.cuda.get_device_name(0)
        info['gpu_memory_gb'] = torch.cuda.get_device_properties(0).total_memory / 1e9
        info['gpu_count'] = torch.cuda.device_count()
    
    return info

def print_device_info():
    """æ‰“å°è®¾å¤‡ä¿¡æ¯"""
    info = get_device_info()
    print('\n' + '='*50)
    print('[DEVICE] è®¾å¤‡é…ç½®')
    print('='*50)
    print(f'å½“å‰è®¾å¤‡: {info["device"]}')
    print(f'é…ç½®USE_CUDA: {info["use_cuda"]}')
    print(f'CUDAå¯ç”¨: {info["cuda_available"]}')
    
    if 'gpu_name' in info:
        print(f'GPUå‹å·: {info["gpu_name"]}')
        print(f'GPUæ˜¾å­˜: {info["gpu_memory_gb"]:.2f} GB')
        print(f'GPUæ•°é‡: {info["gpu_count"]}')
    print('='*50 + '\n')

# ============================================
# å¿«é€Ÿæµ‹è¯•
# ============================================
if __name__ == '__main__':
    print_device_info()
    
    # æµ‹è¯•å¼ é‡åˆ›å»º
    device = get_device()
    x = torch.randn(3, 3).to(device)
    print(f'\næµ‹è¯•å¼ é‡: {x.device}')
    print('[OK] è®¾å¤‡é…ç½®å·¥ä½œæ­£å¸¸ï¼')
